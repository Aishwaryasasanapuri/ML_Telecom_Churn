{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='blue'>Telecom Churn Case Study</font>\n",
    "* Institution: IIIT, Bangalore and UpGrad\n",
    "* Course: PG Diploma in Machine Lerning and AI March 2018\n",
    "* Date: 14-Aug-2018\n",
    "* Submitted by:\n",
    "    1. Pandinath Siddineni (ID- APFE187000194)\n",
    "    2. AKNR Chandra Sekhar (ID- APFE187000315)\n",
    "    3. Brajesh Kumar       (ID- APFE187000149)\n",
    "    4. Shweta Tiwari\n",
    "-----------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='blue'>PART 3: LASSO & DECISSION TREE</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os.path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import datetime as dt\n",
    "\n",
    "pd.options.display.float_format = '{:.2f}'.format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load clean telecom data file\n",
    "master_df = pd.read_csv('telecom_churn_data_clean.csv', low_memory=False)\n",
    "master_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Dataframe Shape: ', master_df.shape)\n",
    "print(\"Dataframe Info: \\n\"); master_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop MemberID/Phone-number\n",
    "telecom = master_df.drop(['mobile_number'], axis=1)\n",
    "\n",
    "# Create X (independent variable) & y (dependent variable) \n",
    "df_telecom = telecom.drop(['churn'], axis=1)\n",
    "X = telecom.drop(['churn'], axis=1)\n",
    "y = telecom['churn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#list(master_df)\n",
    "master_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Standardization/Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "scaler = preprocessing.StandardScaler().fit(X)\n",
    "X = scaler.transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Data into Train & Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Split in train & Test\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, train_size=0.7, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"X_train Dataframe Shape {}\".format(X_train.shape))\n",
    "print(\"X_test Dataframe Shape {}\".format(X_test.shape))\n",
    "\n",
    "y_train_imb = (y_train != 0).sum()/(y_train == 0).sum()\n",
    "y_test_imb = (y_test != 0).sum()/(y_test == 0).sum()\n",
    "print(\"Imbalance in Train Data: {}\".format(y_train_imb))\n",
    "print(\"Imbalance in Test Data: {}\".format(y_test_imb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Balance data set by oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# (Training) Balance Data-Set --- SMOT\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "sm = SMOTE(kind = \"regular\")\n",
    "X_tr,y_tr = sm.fit_sample(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"X_tr Dataframe Shape {}\".format(X_tr.shape))\n",
    "print(\"y_tr Dataframe Shape {}\".format(y_tr.shape))\n",
    "\n",
    "data_imbalance = (y_tr != 0).sum()/(y_tr == 0).sum()\n",
    "print(\"Imbalance in Train Data: {}\".format(data_imbalance))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature reduction using LASSO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    " \n",
    "lsvc = LinearSVC(C=0.02, penalty=\"l1\", dual=False).fit(X_tr, y_tr)\n",
    "model = SelectFromModel(lsvc, prefit=True)\n",
    "X_lasso = model.transform(X_tr)\n",
    "pos = model.get_support(indices=True)\n",
    " ### Feature reduction using RFE\n",
    "print(X_lasso.shape)\n",
    "print(pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#feature vector for decision tree#feature \n",
    "lasso_features = list(df_telecom.columns[pos])\n",
    "print(\"Features identified by LASSO for model buidling: \", lasso_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = X_lasso\n",
    "y_train = y_tr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"Feature space holds %d observations and %d features\" % X_train.shape)\n",
    "print (\"Unique target labels:\", np.unique(y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree with default hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing decision tree classifier from sklearn library\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import tree\n",
    "\n",
    "# Fitting the decision tree with default hyperparameters, apart from\n",
    "# max_depth which is 5 so that we can plot and read the tree.\n",
    "dt_default = DecisionTreeClassifier(max_depth=5)\n",
    "dt_default.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's check the evaluation metrics of our default model\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "# Making predictions\n",
    "X_test = pd.DataFrame(data=X_test).iloc[:, pos]\n",
    "y_pred_default = dt_default.predict(X_test)\n",
    "\n",
    "# Printing classification report\n",
    "print(classification_report(y_test, y_pred_default))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing confusion matrix and accuracy\n",
    "print(confusion_matrix(y_test,y_pred_default))\n",
    "print(accuracy_score(y_test,y_pred_default))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning\n",
    "\n",
    "NOTE: \n",
    "1. Hyperparameter Tunning is commented as it takes heavy computing power and time. It can be run by uncommenting it.\n",
    "2. Getting 86% accuracy that looks to be pretty good."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning max_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # GridSearchCV to find optimal max_depth\n",
    "# from sklearn.model_selection import KFold\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "# # specify number of folds for k-fold CV\n",
    "# n_folds = 5\n",
    "\n",
    "# # parameters to build the model on\n",
    "# parameters = {'max_depth': range(1, 40)}\n",
    "\n",
    "# # instantiate the model\n",
    "# dtree = DecisionTreeClassifier(criterion = \"gini\", \n",
    "#                                random_state = 100)\n",
    "\n",
    "# # fit tree on training data\n",
    "# tree = GridSearchCV(dtree, parameters, \n",
    "#                     cv=n_folds, \n",
    "#                    scoring=\"accuracy\")\n",
    "# tree.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # scores of GridSearch CV\n",
    "# scores = tree.cv_results_\n",
    "# pd.DataFrame(scores).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # plotting accuracies with max_depth\n",
    "# plt.figure()\n",
    "# plt.plot(scores[\"param_max_depth\"], \n",
    "#          scores[\"mean_train_score\"], \n",
    "#          label=\"training accuracy\")\n",
    "# plt.plot(scores[\"param_max_depth\"], \n",
    "#          scores[\"mean_test_score\"], \n",
    "#          label=\"test accuracy\")\n",
    "# plt.xlabel(\"max_depth\")\n",
    "# plt.ylabel(\"Accuracy\")\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "conclusion for max depth:\n",
    "You can see that as we increase the value of max_depth, both training and test score increase till about max-depth = 10, after which the test score is constant. Note that the scores are average accuracies across the 5-folds.\n",
    "\n",
    "we can consider max_depth=10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning min_samples_leaf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # GridSearchCV to find optimal max_depth\n",
    "# from sklearn.model_selection import KFold\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "# # specify number of folds for k-fold CV\n",
    "# n_folds = 5\n",
    "\n",
    "# # parameters to build the model on\n",
    "# parameters = {'min_samples_leaf': range(5, 200, 20)}\n",
    "\n",
    "# # instantiate the model\n",
    "# dtree = DecisionTreeClassifier(criterion = \"gini\", \n",
    "#                                random_state = 100)\n",
    "\n",
    "# # fit tree on training data\n",
    "# tree = GridSearchCV(dtree, parameters, \n",
    "#                     cv=n_folds, \n",
    "#                    scoring=\"accuracy\")\n",
    "# tree.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # scores of GridSearch CV\n",
    "# scores = tree.cv_results_\n",
    "# pd.DataFrame(scores).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # plotting accuracies with min_samples_leaf\n",
    "# plt.figure()\n",
    "# plt.plot(scores[\"param_min_samples_leaf\"], \n",
    "#          scores[\"mean_train_score\"], \n",
    "#          label=\"training accuracy\")\n",
    "# plt.plot(scores[\"param_min_samples_leaf\"], \n",
    "#          scores[\"mean_test_score\"], \n",
    "#          label=\"test accuracy\")\n",
    "# plt.xlabel(\"min_samples_leaf\")\n",
    "# plt.ylabel(\"Accuracy\")\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "conclusion for min_samples_leaf:\n",
    "at low values of min_samples_leaf seems overfitted. At values 125,the model becomes more stable and the training and test accuracy start to converge.\n",
    "min_samples_leaf=125"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning min_samples_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # GridSearchCV to find optimal min_samples_split\n",
    "# from sklearn.model_selection import KFold\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "# # specify number of folds for k-fold CV\n",
    "# n_folds = 5\n",
    "\n",
    "# # parameters to build the model on\n",
    "# parameters = {'min_samples_split': range(5, 200, 20)}\n",
    "\n",
    "# # instantiate the model\n",
    "# dtree = DecisionTreeClassifier(criterion = \"gini\", \n",
    "#                                random_state = 100)\n",
    "\n",
    "# # fit tree on training data\n",
    "# tree = GridSearchCV(dtree, parameters, \n",
    "#                     cv=n_folds, \n",
    "#                    scoring=\"accuracy\")\n",
    "# tree.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # scores of GridSearch CV\n",
    "# scores = tree.cv_results_\n",
    "# pd.DataFrame(scores).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # plotting accuracies with min_samples_leaf\n",
    "# plt.figure()\n",
    "# plt.plot(scores[\"param_min_samples_split\"], \n",
    "#          scores[\"mean_train_score\"], \n",
    "#          label=\"training accuracy\")\n",
    "# plt.plot(scores[\"param_min_samples_split\"], \n",
    "#          scores[\"mean_test_score\"], \n",
    "#          label=\"test accuracy\")\n",
    "# plt.xlabel(\"min_samples_split\")\n",
    "# plt.ylabel(\"Accuracy\")\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "as increase min_samples_split, the tree overfits lesser since the model is less complex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create the parameter grid \n",
    "# param_grid = {\n",
    "#     'max_depth': range(5, 15, 5),\n",
    "#     'min_samples_leaf': range(50, 150, 50),\n",
    "#     'min_samples_split': range(50, 150, 50),\n",
    "#     'criterion': [\"entropy\", \"gini\"]\n",
    "# }\n",
    "\n",
    "# n_folds = 5\n",
    "\n",
    "# # Instantiate the grid search model\n",
    "# dtree = DecisionTreeClassifier()\n",
    "# grid_search = GridSearchCV(estimator = dtree, param_grid = param_grid, \n",
    "#                           cv = n_folds, verbose = 1)\n",
    "\n",
    "# # Fit the grid search to the data\n",
    "# grid_search.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # cv results\n",
    "# cv_results = pd.DataFrame(grid_search.cv_results_)\n",
    "# cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # printing the optimal accuracy score and hyperparameters\n",
    "# print(\"best accuracy\", grid_search.best_score_)\n",
    "# print(grid_search.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # model with optimal hyperparameters\n",
    "# clf_gini = DecisionTreeClassifier(criterion = \"gini\", \n",
    "#                                   random_state = 100,\n",
    "#                                   max_depth=10, \n",
    "#                                   min_samples_leaf=50,\n",
    "#                                   min_samples_split=50)\n",
    "# clf_gini.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # accuracy score\n",
    "# clf_gini.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# <font color='blue'>SUMMARY PART 3: LASSO & DECISSION TREE</font>\n",
    "OBSERVATIONS\n",
    "1. Getting around 86.0% accuracy \n",
    "2. Confusion matix shows lot of false positives still exist.\n",
    "\n",
    "NEXT STEPS:\n",
    "1. Try Random Forrest."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
