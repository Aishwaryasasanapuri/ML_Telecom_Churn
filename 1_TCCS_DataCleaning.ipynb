{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='blue'>Telecom Churn Case Study</font>\n",
    "* Institution: IIIT, Bangalore and UpGrad\n",
    "* Course: PG Diploma in Machine Lerning and AI March 2018\n",
    "* Date: 13-Aug-2018\n",
    "* Submitted by:\n",
    "    1. Pandinath Siddineni (ID- APFE187000194)\n",
    "    2. AKNR Chandra Sekhar\n",
    "    3. Brajesh Kumar\n",
    "    4. Shweta Tiwari\n",
    "-----------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='blue'>Business Goals:</font>\n",
    "1. Retaining high profitable customers is the number one business goal.\n",
    "2. This project is based on the Indian and Southeast Asian market.\n",
    "3. In the Indian and the southeast Asian market, approximately 80% of revenue comes from the top 20% customers (called high-value customers). Thus, if we can reduce churn of the high-value customers, we will be able to reduce significant revenue leakage.\n",
    "4. The business objective is to predict the churn in the last (i.e. the ninth) month using the data (features) from the first three months. To do this task well, understanding the typical customer behaviour during churn will be helpful.\n",
    "\n",
    "## <font color='blue'>Analysis Goals:</font>\n",
    "1. Predict which customers are at high risk of churn\n",
    "2. Build predictive models to identify customers at high risk of churn and identify the main indicators of churn.\n",
    "3. Prepaid is the most common model in India and southeast Asia. Focus on prepaid customers.\n",
    "3. Curn definition used-- \"Usage-based churn: Customers who have not done any usage, either incoming or outgoing - in terms of calls, internet etc. over a period of time.\" In this project, we will use the usage-based definition to define churn.\n",
    "4. In this project, you will define high-value customers based on a certain metric (mentioned later below) and predict churn only on high-value customers.\n",
    "5. especially high-value customers go through  three phases of customer lifecycle: a. The ‘good’ phase, b. The ‘action’ phase, c. The ‘churn’ phase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='blue'>PART 1: DATA CLEANING</font>\n",
    "\n",
    "1. Understand the properties of loaded dataframe\n",
    "2. Idnetify Uniquness key\n",
    "3. Identify bad colums that has no infromation (all entries are null or same)\n",
    "4. Data cleaning to string to numbers (e.g. less than 1 year, 10+ year,)\n",
    "5. Remove columns with data that does not make much sense for our analysis\n",
    "6. Missing value treatment: replace with '0', mean or median; drop rows; drop columns\n",
    "7. Final data_frame for analysis: check for data total data loss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Until fuction: line seperator\n",
    "def print_ln():\n",
    "    print('-'*80, '\\n')\n",
    "\n",
    "# Load csv data file\n",
    "telecom = pd.read_csv('telecom_churn_data.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Understand the properties of loaded dataframe\n",
    "print('Dataframe Shape: ', telecom.shape); print_ln();\n",
    "print(\"Dataframe Info: \\n\"); telecom.info(); print_ln();\n",
    "telecom.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. find high\n",
    "telecom[\"total_rech_amt_6_7\"] = (telecom[\"total_rech_amt_6\"] + telecom[\"total_rech_amt_7\"]) / 2.0\n",
    "amont_70_pc = np.percentile(telecom[\"total_rech_amt_6_7\"], 70.0)\n",
    "print('70 percentile of first two months avg recharge amount: ', amont_70_pc); print_ln();\n",
    "\n",
    "telecom = telecom[telecom[\"total_rech_amt_6_7\"] >= amont_70_pc]\n",
    "print('Dataframe Shape: ', X.shape); print_ln();\n",
    "\n",
    "\n",
    "X = telecom[\"total_ic_mou_9\"] + telecom[\"total_og_mou_9\"] + telecom[\"vol_2g_mb_9\"] + telecom[\"vol_3g_mb_9\"]\n",
    "telecom[\"churn\"] = np.where(X, 0, 1)\n",
    "#telecom[\"churn\"].head(30)\n",
    "drop_columns = [\"total_ic_mou_9\", \"total_og_mou_9\", \"vol_2g_mb_9\", \"vol_3g_mb_9\"]\n",
    "\n",
    "\n",
    "# 2. Unique Key Analysis\n",
    "telecom_unique_count = telecom.nunique().sort_values(ascending=False)\n",
    "print(\"Dataframe Unique Values: \\n\", telecom_unique_count); print_ln()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Identify bad colums that has no infromation (all entries are NA or same)\n",
    "# Find columns with all NULL entries and add to drop_columns list\n",
    "telecom_unique_count_is_zero = telecom_unique_count[telecom_unique_count == 0]\n",
    "print(\"Dataframe Unique Value Count is ZERO (all null values): \\n\", telecom_unique_count_is_zero); print_ln();\n",
    "\n",
    "\n",
    "# Find columns with all same entries and add to drop_columns list\n",
    "telecom_unique_count_is_one = telecom_unique_count[telecom_unique_count == 1]\n",
    "print(\"Dataframe Unique Value Count is ONE (all same values): \\n\", telecom_unique_count_is_one); print_ln();\n",
    "drop_columns += list(telecom_unique_count_is_one.index)\n",
    "\n",
    "print('Number of columns to drop after uniqness check = ', len(drop_columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop all identified columns\n",
    "telecom.drop(drop_columns, axis=1, inplace=True)\n",
    "print('Dataframe Shape: ', telecom.shape); print_ln();\n",
    "print(\"Dataframe Info: \\n\"); telecom.info(); print_ln();\n",
    "telecom.head(5) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reduce numbner of features\n",
    "- LASSO / RIDGE\n",
    "- PCA\n",
    "- RFE\n",
    "- ELASTIC NET\n",
    "- DECISSION CLASSIFIER (FORREST TREE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 4. Data cleaning to string to numbers (e.g. less than 1 year, 10+ year,) \n",
    "# #telecom = telecom_backup.copy() \n",
    "# #-------------------------------------------------------------------------------\n",
    "# # COLUMN 'term': remove non numeric charectors \"months\" and convert to int\n",
    "# print(telecom['term'].dtype)\n",
    "# if telecom['term'].dtype == object: \n",
    "#     telecom['term'] = telecom.term.str.extract('(\\d+)', expand=False).astype(int)\n",
    "\n",
    "# #-------------------------------------------------------------------------------\n",
    "# # COLUMN 'int_rate': remove % and covert to float\n",
    "# if telecom['int_rate'].dtype == object: \n",
    "#     telecom['int_rate'] = telecom.int_rate.str.extract('(\\d+)', expand=False).astype(float)\n",
    "\n",
    "# #-------------------------------------------------------------------------------\n",
    "# # COLUMN 'revol_util': remove % and convert to float\n",
    "# # Null value treatment: after discussing with domain expert, we decided to replace them with 0\n",
    "# if telecom['revol_util'].dtype == object: \n",
    "#     telecom['revol_util'] = telecom.revol_util.fillna(\"0\").str.extract('(\\d+)', expand=False).astype(float)\n",
    "\n",
    "# #-------------------------------------------------------------------------------\n",
    "# # COLUMN 'emp_length': remove non numeric charectors\n",
    "# # Null value treatment: after discussing with domain expert, we decided to replace median\n",
    "# # 0-1 yrs  =  0\n",
    "# # 1-2 yrs  =  1\n",
    "# # 2-3 yrs  =  2\n",
    "# # .............\n",
    "# # 9-10 yrs =  9\n",
    "# # 10+ yrs  = 10\n",
    "# # n/a      = median (choosen median as it represent better approximation)\n",
    "\n",
    "# #print(telecom['emp_length'].unique()); print_ln()\n",
    "# if telecom['emp_length'].dtype == object: \n",
    "#     telecom['emp_length'] = telecom.emp_length.str.extract('(\\d+)', expand=False)\n",
    "#     #print(telecom['emp_length'].median()); print_ln()\n",
    "#     telecom['emp_length'] = telecom['emp_length'].fillna(telecom.emp_length.median()).astype(int)\n",
    "#     #print(telecom['emp_length'].unique()); print_ln()\n",
    "#     #print(telecom['emp_length'].describe()); print_ln()\n",
    "#     #print(telecom['emp_length'].median()); print_ln()\n",
    "    \n",
    "# #-------------------------------------------------------------------------------\n",
    "# # COLUMN 'last_pymnt_amnt': has mixed data type conver all to float\n",
    "# telecom['last_pymnt_amnt'] = telecom['last_pymnt_amnt'].astype(float)\n",
    "\n",
    "# print(telecom[['term', 'int_rate', 'revol_util', 'emp_length']].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 5. Remove columns with data that does not make much sense for our analysis\n",
    "# # FINDINGS: resons for dropping columns\n",
    "# # COLUMN 'desc': running text & date- no meaningful insigth\n",
    "# # COLUMN 'emp_title': shows address, names, description and does not give any meaningful insight\n",
    "# # COLUMN 'title': contians numbers, year, date, telecom type, amount- no meaningful insigth\n",
    "# drop_columns = ['desc', 'emp_title', 'title']\n",
    "# telecom.drop(drop_columns, axis=1, inplace=True)\n",
    "\n",
    "# print('Dataframe Shape: ', telecom.shape); print_ln();\n",
    "# print(\"Dataframe Info: \\n\"); telecom.info(); print_ln();\n",
    "# telecom.head(5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 6. Missing Value Treatment\n",
    "# #print(\"\\nCount null values in each column: \\n\", telecom.isnull().sum()); print_ln()\n",
    "# print(\"\\n% of null values in each column: \\n\", round(100*(telecom.isnull().sum()/len(telecom.index)), 2)); print_ln()\n",
    "\n",
    "# # drop COLUMN 'mths_since_last_record' with 94.64% missing values\n",
    "# telecom.drop('mths_since_last_record', axis=1, inplace=True)\n",
    "\n",
    "# # drop COLUMN 'next_pymnt_d' with 97.07% missing values\n",
    "# telecom.drop('next_pymnt_d', axis=1, inplace=True)\n",
    "\n",
    "# # remove ROW with null values (0.18%) for 'last_pymnt_d'\n",
    "# telecom = telecom[~telecom['last_pymnt_d'].isnull()]\n",
    "\n",
    "# # remove ROW with null values (0.01%) for 'last_credit_pull_d'\n",
    "# telecom = telecom[~telecom['last_credit_pull_d'].isnull()]\n",
    "\n",
    "# # remove ROW with null values (1.75%) for 'pub_rec_bankruptcies'\n",
    "# # check unique values\n",
    "# print(telecom['pub_rec_bankruptcies'].unique()); print_ln()\n",
    "# telecom = telecom[~telecom['pub_rec_bankruptcies'].isnull()]\n",
    "\n",
    "# #print(\"\\n% of Null values in each column: \\n\", round(100*(telecom.isnull().sum()/len(telecom.index)), 2)); print_ln()\n",
    "\n",
    "# print(\"\\nNull values in each row: \", telecom.isnull().all(axis=1).sum()); print_ln()\n",
    "# print('Dataframe Shape: ', telecom.shape); print_ln();\n",
    "# print(\"\\n% of Null values in each column: \\n\", round(100*(telecom.isnull().sum()/len(telecom.index)), 2)); print_ln()\n",
    "# telecom.head(5) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # write treated telecom file\n",
    "# telecom.to_csv(\"telecom_clean.csv\", sep=',', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='blue'>SUMMARY: DATA CLEANING</font>\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
