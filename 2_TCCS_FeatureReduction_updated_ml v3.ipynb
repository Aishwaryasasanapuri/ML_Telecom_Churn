{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='blue'>Telecom Churn Case Study</font>\n",
    "* Institution: IIIT, Bangalore and UpGrad\n",
    "* Course: PG Diploma in Machine Lerning and AI March 2018\n",
    "* Date: 14-Aug-2018\n",
    "* Submitted by:\n",
    "    1. Pandinath Siddineni (ID- APFE187000194)\n",
    "    2. AKNR Chandra Sekhar (ID- APFE187000315)\n",
    "    3. Brajesh Kumar       (ID- APFE187000149)\n",
    "    4. Shweta Tiwari\n",
    "-----------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='blue'>PART 3: FEATURE REDUCTION USING PCA</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.float_format = '{:.2f}'.format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load clean telecom data file\n",
    "master_df = pd.read_csv('E:\\IIIT Bangalore AIML\\Group Assignment 2\\\\telecom_churn_data_clean2.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mobile_number</th>\n",
       "      <th>onnet_mou_6</th>\n",
       "      <th>onnet_mou_7</th>\n",
       "      <th>onnet_mou_8</th>\n",
       "      <th>offnet_mou_6</th>\n",
       "      <th>offnet_mou_7</th>\n",
       "      <th>offnet_mou_8</th>\n",
       "      <th>roam_ic_mou_6</th>\n",
       "      <th>roam_ic_mou_7</th>\n",
       "      <th>roam_ic_mou_8</th>\n",
       "      <th>...</th>\n",
       "      <th>rech_days_left_data_7</th>\n",
       "      <th>rech_days_left_8</th>\n",
       "      <th>rech_days_left_data_8</th>\n",
       "      <th>churn</th>\n",
       "      <th>night_pck_churn_6</th>\n",
       "      <th>night_pck_churn_7</th>\n",
       "      <th>night_pck_churn_8</th>\n",
       "      <th>fb_churn_6</th>\n",
       "      <th>fb_churn_7</th>\n",
       "      <th>fb_churn_8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7000701601</td>\n",
       "      <td>57.84</td>\n",
       "      <td>54.68</td>\n",
       "      <td>52.29</td>\n",
       "      <td>453.43</td>\n",
       "      <td>567.16</td>\n",
       "      <td>325.91</td>\n",
       "      <td>16.23</td>\n",
       "      <td>33.49</td>\n",
       "      <td>31.64</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7002311591</td>\n",
       "      <td>288.56</td>\n",
       "      <td>376.66</td>\n",
       "      <td>111.61</td>\n",
       "      <td>186.59</td>\n",
       "      <td>1326.06</td>\n",
       "      <td>771.14</td>\n",
       "      <td>52.96</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7.28</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7000959346</td>\n",
       "      <td>120.19</td>\n",
       "      <td>236.14</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2082.18</td>\n",
       "      <td>2532.03</td>\n",
       "      <td>408.54</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7000104470</td>\n",
       "      <td>1241.99</td>\n",
       "      <td>1026.66</td>\n",
       "      <td>0.00</td>\n",
       "      <td>112.91</td>\n",
       "      <td>115.13</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.38</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7000409785</td>\n",
       "      <td>424.98</td>\n",
       "      <td>328.73</td>\n",
       "      <td>363.98</td>\n",
       "      <td>457.09</td>\n",
       "      <td>361.34</td>\n",
       "      <td>391.68</td>\n",
       "      <td>315.29</td>\n",
       "      <td>303.04</td>\n",
       "      <td>254.34</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 144 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mobile_number  onnet_mou_6  onnet_mou_7  onnet_mou_8  offnet_mou_6  \\\n",
       "0     7000701601        57.84        54.68        52.29        453.43   \n",
       "1     7002311591       288.56       376.66       111.61        186.59   \n",
       "2     7000959346       120.19       236.14         1.71       2082.18   \n",
       "3     7000104470      1241.99      1026.66         0.00        112.91   \n",
       "4     7000409785       424.98       328.73       363.98        457.09   \n",
       "\n",
       "   offnet_mou_7  offnet_mou_8  roam_ic_mou_6  roam_ic_mou_7  roam_ic_mou_8  \\\n",
       "0        567.16        325.91          16.23          33.49          31.64   \n",
       "1       1326.06        771.14          52.96           0.00           7.28   \n",
       "2       2532.03        408.54           0.00           0.00           0.00   \n",
       "3        115.13          0.00           0.00           0.00           0.38   \n",
       "4        361.34        391.68         315.29         303.04         254.34   \n",
       "\n",
       "      ...      rech_days_left_data_7  rech_days_left_8  rech_days_left_data_8  \\\n",
       "0     ...                       0.00              5.00                   0.00   \n",
       "1     ...                       0.00              6.00                   0.00   \n",
       "2     ...                       0.00              3.00                   0.00   \n",
       "3     ...                       0.00              2.00                   0.00   \n",
       "4     ...                       0.00              1.00                   0.00   \n",
       "\n",
       "   churn  night_pck_churn_6  night_pck_churn_7  night_pck_churn_8  fb_churn_6  \\\n",
       "0      1               0.07               0.08               0.09        0.07   \n",
       "1      1               0.07               0.08               0.09        0.07   \n",
       "2      1               0.07               0.08               0.09        0.07   \n",
       "3      1               0.07               0.08               0.09        0.07   \n",
       "4      1               0.07               0.08               0.09        0.07   \n",
       "\n",
       "   fb_churn_7  fb_churn_8  \n",
       "0        0.08        0.09  \n",
       "1        0.08        0.09  \n",
       "2        0.08        0.09  \n",
       "3        0.08        0.09  \n",
       "4        0.08        0.09  \n",
       "\n",
       "[5 rows x 144 columns]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['mobile_number',\n",
       " 'onnet_mou_6',\n",
       " 'onnet_mou_7',\n",
       " 'onnet_mou_8',\n",
       " 'offnet_mou_6',\n",
       " 'offnet_mou_7',\n",
       " 'offnet_mou_8',\n",
       " 'roam_ic_mou_6',\n",
       " 'roam_ic_mou_7',\n",
       " 'roam_ic_mou_8',\n",
       " 'roam_og_mou_6',\n",
       " 'roam_og_mou_7',\n",
       " 'roam_og_mou_8',\n",
       " 'loc_og_t2t_mou_6',\n",
       " 'loc_og_t2t_mou_7',\n",
       " 'loc_og_t2t_mou_8',\n",
       " 'loc_og_t2m_mou_6',\n",
       " 'loc_og_t2m_mou_7',\n",
       " 'loc_og_t2m_mou_8',\n",
       " 'loc_og_t2f_mou_6',\n",
       " 'loc_og_t2f_mou_7',\n",
       " 'loc_og_t2f_mou_8',\n",
       " 'loc_og_t2c_mou_6',\n",
       " 'loc_og_t2c_mou_7',\n",
       " 'loc_og_t2c_mou_8',\n",
       " 'loc_og_mou_6',\n",
       " 'loc_og_mou_7',\n",
       " 'loc_og_mou_8',\n",
       " 'std_og_t2t_mou_6',\n",
       " 'std_og_t2t_mou_7',\n",
       " 'std_og_t2t_mou_8',\n",
       " 'std_og_t2m_mou_6',\n",
       " 'std_og_t2m_mou_7',\n",
       " 'std_og_t2m_mou_8',\n",
       " 'std_og_t2f_mou_6',\n",
       " 'std_og_t2f_mou_7',\n",
       " 'std_og_t2f_mou_8',\n",
       " 'std_og_mou_6',\n",
       " 'std_og_mou_7',\n",
       " 'std_og_mou_8',\n",
       " 'isd_og_mou_6',\n",
       " 'isd_og_mou_7',\n",
       " 'isd_og_mou_8',\n",
       " 'spl_og_mou_6',\n",
       " 'spl_og_mou_7',\n",
       " 'spl_og_mou_8',\n",
       " 'og_others_6',\n",
       " 'og_others_7',\n",
       " 'og_others_8',\n",
       " 'total_og_mou_6',\n",
       " 'total_og_mou_7',\n",
       " 'total_og_mou_8',\n",
       " 'loc_ic_t2t_mou_6',\n",
       " 'loc_ic_t2t_mou_7',\n",
       " 'loc_ic_t2t_mou_8',\n",
       " 'loc_ic_t2m_mou_6',\n",
       " 'loc_ic_t2m_mou_7',\n",
       " 'loc_ic_t2m_mou_8',\n",
       " 'loc_ic_t2f_mou_6',\n",
       " 'loc_ic_t2f_mou_7',\n",
       " 'loc_ic_t2f_mou_8',\n",
       " 'loc_ic_mou_6',\n",
       " 'loc_ic_mou_7',\n",
       " 'loc_ic_mou_8',\n",
       " 'std_ic_t2t_mou_6',\n",
       " 'std_ic_t2t_mou_7',\n",
       " 'std_ic_t2t_mou_8',\n",
       " 'std_ic_t2m_mou_6',\n",
       " 'std_ic_t2m_mou_7',\n",
       " 'std_ic_t2m_mou_8',\n",
       " 'std_ic_t2f_mou_6',\n",
       " 'std_ic_t2f_mou_7',\n",
       " 'std_ic_t2f_mou_8',\n",
       " 'std_ic_mou_6',\n",
       " 'std_ic_mou_7',\n",
       " 'std_ic_mou_8',\n",
       " 'total_ic_mou_6',\n",
       " 'total_ic_mou_7',\n",
       " 'total_ic_mou_8',\n",
       " 'spl_ic_mou_6',\n",
       " 'spl_ic_mou_7',\n",
       " 'spl_ic_mou_8',\n",
       " 'isd_ic_mou_6',\n",
       " 'isd_ic_mou_7',\n",
       " 'isd_ic_mou_8',\n",
       " 'ic_others_6',\n",
       " 'ic_others_7',\n",
       " 'ic_others_8',\n",
       " 'total_rech_amt_6',\n",
       " 'total_rech_amt_7',\n",
       " 'total_rech_amt_8',\n",
       " 'max_rech_amt_6',\n",
       " 'max_rech_amt_7',\n",
       " 'max_rech_amt_8',\n",
       " 'last_day_rch_amt_6',\n",
       " 'last_day_rch_amt_7',\n",
       " 'last_day_rch_amt_8',\n",
       " 'total_rech_data_6',\n",
       " 'total_rech_data_7',\n",
       " 'total_rech_data_8',\n",
       " 'max_rech_data_6',\n",
       " 'max_rech_data_7',\n",
       " 'max_rech_data_8',\n",
       " 'vol_2g_mb_6',\n",
       " 'vol_2g_mb_7',\n",
       " 'vol_2g_mb_8',\n",
       " 'vol_3g_mb_6',\n",
       " 'vol_3g_mb_7',\n",
       " 'vol_3g_mb_8',\n",
       " 'night_pck_user_6',\n",
       " 'night_pck_user_7',\n",
       " 'night_pck_user_8',\n",
       " 'monthly_2g_6',\n",
       " 'monthly_2g_7',\n",
       " 'monthly_2g_8',\n",
       " 'sachet_2g_6',\n",
       " 'sachet_2g_7',\n",
       " 'sachet_2g_8',\n",
       " 'monthly_3g_6',\n",
       " 'monthly_3g_7',\n",
       " 'monthly_3g_8',\n",
       " 'sachet_3g_6',\n",
       " 'sachet_3g_7',\n",
       " 'sachet_3g_8',\n",
       " 'fb_user_6',\n",
       " 'fb_user_7',\n",
       " 'fb_user_8',\n",
       " 'aon',\n",
       " 'total_rech_data_amt_6',\n",
       " 'total_rech_data_amt_7',\n",
       " 'total_rech_data_amt_8',\n",
       " 'rech_days_left_6',\n",
       " 'rech_days_left_data_6',\n",
       " 'rech_days_left_7',\n",
       " 'rech_days_left_data_7',\n",
       " 'rech_days_left_8',\n",
       " 'rech_days_left_data_8',\n",
       " 'churn',\n",
       " 'night_pck_churn_6',\n",
       " 'night_pck_churn_7',\n",
       " 'night_pck_churn_8',\n",
       " 'fb_churn_6',\n",
       " 'fb_churn_7',\n",
       " 'fb_churn_8']"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(master_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28504, 144)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "telecom = master_df.drop(['mobile_number'], 1)\n",
    "telecom = telecom.drop(['fb_user_6', 'fb_user_7', 'fb_user_8', 'night_pck_user_6', 'night_pck_user_7', 'night_pck_user_8'], 1)\n",
    "#telecom = telecom.drop(['fb_churn_6', 'fb_churn_7', 'fb_churn_8', 'night_pck_churn_6', 'night_pck_churn_7', 'night_pck_churn_8'], 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>onnet_mou_6</th>\n",
       "      <th>onnet_mou_7</th>\n",
       "      <th>onnet_mou_8</th>\n",
       "      <th>offnet_mou_6</th>\n",
       "      <th>offnet_mou_7</th>\n",
       "      <th>offnet_mou_8</th>\n",
       "      <th>roam_ic_mou_6</th>\n",
       "      <th>roam_ic_mou_7</th>\n",
       "      <th>roam_ic_mou_8</th>\n",
       "      <th>roam_og_mou_6</th>\n",
       "      <th>...</th>\n",
       "      <th>rech_days_left_data_7</th>\n",
       "      <th>rech_days_left_8</th>\n",
       "      <th>rech_days_left_data_8</th>\n",
       "      <th>churn</th>\n",
       "      <th>night_pck_churn_6</th>\n",
       "      <th>night_pck_churn_7</th>\n",
       "      <th>night_pck_churn_8</th>\n",
       "      <th>fb_churn_6</th>\n",
       "      <th>fb_churn_7</th>\n",
       "      <th>fb_churn_8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>57.84</td>\n",
       "      <td>54.68</td>\n",
       "      <td>52.29</td>\n",
       "      <td>453.43</td>\n",
       "      <td>567.16</td>\n",
       "      <td>325.91</td>\n",
       "      <td>16.23</td>\n",
       "      <td>33.49</td>\n",
       "      <td>31.64</td>\n",
       "      <td>23.74</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>288.56</td>\n",
       "      <td>376.66</td>\n",
       "      <td>111.61</td>\n",
       "      <td>186.59</td>\n",
       "      <td>1326.06</td>\n",
       "      <td>771.14</td>\n",
       "      <td>52.96</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7.28</td>\n",
       "      <td>10.69</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>120.19</td>\n",
       "      <td>236.14</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2082.18</td>\n",
       "      <td>2532.03</td>\n",
       "      <td>408.54</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1241.99</td>\n",
       "      <td>1026.66</td>\n",
       "      <td>0.00</td>\n",
       "      <td>112.91</td>\n",
       "      <td>115.13</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>424.98</td>\n",
       "      <td>328.73</td>\n",
       "      <td>363.98</td>\n",
       "      <td>457.09</td>\n",
       "      <td>361.34</td>\n",
       "      <td>391.68</td>\n",
       "      <td>315.29</td>\n",
       "      <td>303.04</td>\n",
       "      <td>254.34</td>\n",
       "      <td>613.84</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 137 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   onnet_mou_6  onnet_mou_7  onnet_mou_8  offnet_mou_6  offnet_mou_7  \\\n",
       "0        57.84        54.68        52.29        453.43        567.16   \n",
       "1       288.56       376.66       111.61        186.59       1326.06   \n",
       "2       120.19       236.14         1.71       2082.18       2532.03   \n",
       "3      1241.99      1026.66         0.00        112.91        115.13   \n",
       "4       424.98       328.73       363.98        457.09        361.34   \n",
       "\n",
       "   offnet_mou_8  roam_ic_mou_6  roam_ic_mou_7  roam_ic_mou_8  roam_og_mou_6  \\\n",
       "0        325.91          16.23          33.49          31.64          23.74   \n",
       "1        771.14          52.96           0.00           7.28          10.69   \n",
       "2        408.54           0.00           0.00           0.00           0.00   \n",
       "3          0.00           0.00           0.00           0.38           0.00   \n",
       "4        391.68         315.29         303.04         254.34         613.84   \n",
       "\n",
       "      ...      rech_days_left_data_7  rech_days_left_8  rech_days_left_data_8  \\\n",
       "0     ...                       0.00              5.00                   0.00   \n",
       "1     ...                       0.00              6.00                   0.00   \n",
       "2     ...                       0.00              3.00                   0.00   \n",
       "3     ...                       0.00              2.00                   0.00   \n",
       "4     ...                       0.00              1.00                   0.00   \n",
       "\n",
       "   churn  night_pck_churn_6  night_pck_churn_7  night_pck_churn_8  fb_churn_6  \\\n",
       "0      1               0.07               0.08               0.09        0.07   \n",
       "1      1               0.07               0.08               0.09        0.07   \n",
       "2      1               0.07               0.08               0.09        0.07   \n",
       "3      1               0.07               0.08               0.09        0.07   \n",
       "4      1               0.07               0.08               0.09        0.07   \n",
       "\n",
       "   fb_churn_7  fb_churn_8  \n",
       "0        0.08        0.09  \n",
       "1        0.08        0.09  \n",
       "2        0.08        0.09  \n",
       "3        0.08        0.09  \n",
       "4        0.08        0.09  \n",
       "\n",
       "[5 rows x 137 columns]"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "telecom.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# applying SMOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting the data into train and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "X = telecom.drop(['churn'],axis=1)\n",
    "y = telecom['churn']\n",
    "sm = SMOTE(kind = \"regular\")\n",
    "X_tr,y_tr = sm.fit_sample(X,y)\n",
    "print(X_tr.shape)\n",
    "print(y_tr.shape)\n",
    "np.count_nonzero(y_tr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X_tr = X\n",
    "y_tr = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Users\\Aknrcsekhar\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_tr,y_tr, train_size=0.7,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn import preprocessing\n",
    "\n",
    "scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "x_scaled = scaler.fit_transform(X_train)\n",
    "X_test=scaler.transform(X_test)\n",
    "X_train=scaler.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.62777375, -0.60098282, -0.46519933, ..., -0.84595238,\n",
       "        -0.4232551 , -0.08164746],\n",
       "       [-0.48174232, -0.47902168,  0.61350149, ...,  1.10495341,\n",
       "         0.11583577, -0.58357549],\n",
       "       [-0.64347844, -0.60164784, -0.36403901, ..., -0.84595238,\n",
       "        -0.96234597, -0.58357549],\n",
       "       ...,\n",
       "       [ 0.77843314,  0.63642298, -0.34771281, ..., -0.84595238,\n",
       "        -0.78264902, -0.58357549],\n",
       "       [-0.3310015 , -0.31335041,  0.50971177, ..., -0.11436271,\n",
       "        -0.78264902, -0.45809349],\n",
       "       [-0.65132068, -0.62530653, -0.64956833, ..., -0.84595238,\n",
       "        -0.60295206, -0.33261148]])"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.48485208e+00,  7.15652126e-01, -5.83202401e-01, ...,\n",
       "         1.41140684e+00,  1.84219609e-01,  1.85976968e-01],\n",
       "       [ 3.34741402e+00,  5.12838963e+00, -2.39859456e-01, ...,\n",
       "        -8.45952377e-01, -9.62345973e-01, -5.83575495e-01],\n",
       "       [-2.58400129e-01, -3.50893963e-01, -6.87809034e-02, ...,\n",
       "        -3.58225930e-01, -6.38611890e-02, -5.83575495e-01],\n",
       "       ...,\n",
       "       [-3.56569632e-01, -2.88966239e-01,  3.33422215e-01, ...,\n",
       "        -1.14362707e-01, -6.02952059e-01, -5.83575495e-01],\n",
       "       [-4.71978477e-03, -2.41124906e-01,  4.90469314e-01, ...,\n",
       "        -8.45952377e-01, -6.02952059e-01, -5.83575495e-01],\n",
       "       [ 1.67574868e+00,  6.99744210e-01, -5.23396493e-01, ...,\n",
       "         1.88175153e+00,  4.26438011e-02, -5.83575495e-01]])"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# applying SVM kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "from sklearn.svm import SVC\n",
    "model = SVC(C = 1, kernel='rbf')\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "# confusion matrix\n",
    "confusion_matrix(y_true=y_test, y_pred=y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Printing classification report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# applying decision tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing decision tree classifier from sklearn library\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import tree\n",
    "\n",
    "# Fitting the decision tree with default hyperparameters, apart from\n",
    "# max_depth which is 5 so that we can plot and read the tree.\n",
    "dt_default = DecisionTreeClassifier(max_depth=5)\n",
    "dt_default.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's check the evaluation metrics of our default model\n",
    "\n",
    "# Importing classification report and confusion matrix from sklearn metrics\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "# Making predictions\n",
    "y_pred_default = dt_default.predict(X_test)\n",
    "\n",
    "# Printing classification report\n",
    "print(classification_report(y_test, y_pred_default))\n",
    "\n",
    "print(y_pred_default)\n",
    "print(y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# feature extraction using lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26342, 63)\n",
      "[ 0  1  3  4  7  8  9 10 11 12 14 15 16 17 18 19 20 21 22 24 25 27 28 29\n",
      " 30 31 32 33 34 36 37 38 39 41 42 43 44 45 46 47 48 49 51 52 53 54 55 56\n",
      " 57 58 59 60 61 62 63 65 66 67 68 69 70 71 72]\n",
      "(11290, 63)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    " \n",
    "lsvc = LinearSVC(C=0.02, penalty=\"l1\", dual=False).fit(X_train,y_train)\n",
    "model = SelectFromModel(lsvc, prefit=True)\n",
    "X_train_transformed = model.transform(X_train)\n",
    "pos = model.get_support(indices=True)\n",
    " \n",
    "print(X_train_transformed.shape)\n",
    "print(pos)\n",
    " \n",
    "X_test_transformed = model.transform(X_test)\n",
    "print(X_test_transformed.shape) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26424, 63)\n",
      "(26424,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "13212"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Splitting the data into train and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "X = X_train_transformed  #telecom.drop(['churn'],axis=1)\n",
    "y = y_train  #telecom['churn']\n",
    "sm = SMOTE(kind = \"regular\")\n",
    "X_tr,y_tr = sm.fit_sample(X,y)\n",
    "print(X_tr.shape)\n",
    "print(y_tr.shape)\n",
    "np.count_nonzero(y_tr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# applying linear SVC after lasso (Need to be removed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model = SVC(C = 1)\n",
    "model.fit(X_train_transformed, y_train)\n",
    "y_pred = model.predict(X_test_transformed)\n",
    "confusion_matrix(y_true=y_test, y_pred=y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# applying decision tree after lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=5,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing decision tree classifier from sklearn library\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import tree\n",
    "\n",
    "# Fitting the decision tree with default hyperparameters, apart from\n",
    "# max_depth which is 5 so that we can plot and read the tree.\n",
    "dt_default = DecisionTreeClassifier(max_depth=5)\n",
    "dt_default.fit(X_tr, y_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      0.88      0.89      5604\n",
      "          1       0.88      0.89      0.89      5686\n",
      "\n",
      "avg / total       0.89      0.89      0.89     11290\n",
      "\n",
      "[1 0 0 ... 0 0 1]\n",
      "[1 0 0 ... 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "# Let's check the evaluation metrics of our default model\n",
    "\n",
    "# Importing classification report and confusion matrix from sklearn metrics\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "# Making predictions\n",
    "y_pred_default = dt_default.predict(X_test_transformed)\n",
    "\n",
    "# Printing classification report\n",
    "print(classification_report(y_test, y_pred_default))\n",
    "\n",
    "print(y_pred_default)\n",
    "print(y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4943  661]\n",
      " [ 622 5064]]\n"
     ]
    }
   ],
   "source": [
    "# Printing confusion matrix\n",
    "print(confusion_matrix(y_test,y_pred_default))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8863596102745793\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_test,y_pred_default))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# applying default random forest after lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing random forest classifier from sklearn library\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Running the random forest with default parameters.\n",
    "rfc = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit\n",
    "#rfc.fit(X_train_transformed,y_train)\n",
    "rfc.fit(X_tr,y_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making predictions\n",
    "predictions = rfc.predict(X_test_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      0.97      0.96      5604\n",
      "          1       0.97      0.96      0.96      5686\n",
      "\n",
      "avg / total       0.96      0.96      0.96     11290\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Let's check the report of our default model\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "print(classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5408  196]\n",
      " [ 207 5479]]\n"
     ]
    }
   ],
   "source": [
    "# Printing confusion matrix\n",
    "print(confusion_matrix(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9643046944198406\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_test,predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# applying PCA and Logistic regression after lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PCA(copy=True, iterated_power='auto', n_components=None, random_state=100,\n",
       "  svd_solver='auto', tol=0.0, whiten=False)"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Improting the PCA module\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(random_state=100)\n",
    "\n",
    "#Doing the PCA on the train data\n",
    "pca.fit(X_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([11.3 , 21.19, 27.49, 33.15, 36.99, 40.67, 44.17, 47.01, 49.62,\n",
       "       52.2 , 54.43, 56.51, 58.57, 60.49, 62.3 , 64.09, 65.82, 67.51,\n",
       "       69.17, 70.72, 72.25, 73.75, 75.22, 76.62, 78.02, 79.32, 80.53,\n",
       "       81.71, 82.87, 83.97, 85.02, 86.05, 87.07, 87.99, 88.84, 89.65,\n",
       "       90.41, 91.17, 91.9 , 92.56, 93.16, 93.75, 94.33, 94.84, 95.34,\n",
       "       95.83, 96.28, 96.71, 97.13, 97.53, 97.88, 98.22, 98.54, 98.82,\n",
       "       99.05, 99.26, 99.41, 99.55, 99.69, 99.82, 99.9 , 99.97, 99.99])"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.cumsum(np.round(pca.explained_variance_ratio_, decimals=4)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26424, 63)\n",
      "(11290, 63)\n"
     ]
    }
   ],
   "source": [
    "df_train_pca = pca.fit_transform(X_tr)\n",
    "print(df_train_pca.shape)\n",
    "\n",
    "df_test_pca = pca.transform(X_test_transformed)\n",
    "print(df_test_pca.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's run the model using the selected variables\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "logsk = LogisticRegression(C=1e9)\n",
    "#logsk.fit(X_train[col], y_train)\n",
    "logsk.fit(df_train_pca, y_tr)\n",
    "\n",
    "#predict()\n",
    "# Predicted probabilities\n",
    "y_pred = logsk.predict(df_test_pca)\n",
    "# Converting y_pred to a dataframe which is an array\n",
    "y_pred_df = pd.DataFrame(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4624  980]\n",
      " [ 793 4893]]\n"
     ]
    }
   ],
   "source": [
    "# Printing confusion matrix\n",
    "print(confusion_matrix(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8429583702391497\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.15704162976085032\n",
      "0.3718003421002486\n"
     ]
    }
   ],
   "source": [
    "r_squared = r2_score(y_test, y_pred)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "print(mse)\n",
    "\n",
    "print(r_squared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'max_depth': range(2, 20, 5)}, pre_dispatch='2*n_jobs',\n",
       "       refit=True, return_train_score=True, scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GridSearchCV to find optimal n_estimators\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "# specify number of folds for k-fold CV\n",
    "n_folds = 5\n",
    "\n",
    "# parameters to build the model on\n",
    "parameters = {'max_depth': range(2, 20, 5)}\n",
    "\n",
    "# instantiate the model\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "\n",
    "# fit tree on training data\n",
    "rf = GridSearchCV(rf, parameters, \n",
    "                    cv=n_folds, \n",
    "                   scoring=\"accuracy\")\n",
    "rf.fit(X_train_transformed, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>params</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.48</td>\n",
       "      <td>0.02</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2</td>\n",
       "      <td>{'max_depth': 2}</td>\n",
       "      <td>4</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.67</td>\n",
       "      <td>0.02</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>7</td>\n",
       "      <td>{'max_depth': 7}</td>\n",
       "      <td>1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.63</td>\n",
       "      <td>0.02</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>12</td>\n",
       "      <td>{'max_depth': 12}</td>\n",
       "      <td>1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.67</td>\n",
       "      <td>0.02</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>17</td>\n",
       "      <td>{'max_depth': 17}</td>\n",
       "      <td>1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  mean_score_time  mean_test_score  mean_train_score  \\\n",
       "0           0.48             0.02             1.00              1.00   \n",
       "1           0.67             0.02             1.00              1.00   \n",
       "2           0.63             0.02             1.00              1.00   \n",
       "3           0.67             0.02             1.00              1.00   \n",
       "\n",
       "  param_max_depth             params  rank_test_score  split0_test_score  \\\n",
       "0               2   {'max_depth': 2}                4               1.00   \n",
       "1               7   {'max_depth': 7}                1               1.00   \n",
       "2              12  {'max_depth': 12}                1               1.00   \n",
       "3              17  {'max_depth': 17}                1               1.00   \n",
       "\n",
       "   split0_train_score  split1_test_score       ...         split2_test_score  \\\n",
       "0                1.00               1.00       ...                      1.00   \n",
       "1                1.00               1.00       ...                      1.00   \n",
       "2                1.00               1.00       ...                      1.00   \n",
       "3                1.00               1.00       ...                      1.00   \n",
       "\n",
       "   split2_train_score  split3_test_score  split3_train_score  \\\n",
       "0                1.00               1.00                1.00   \n",
       "1                1.00               1.00                1.00   \n",
       "2                1.00               1.00                1.00   \n",
       "3                1.00               1.00                1.00   \n",
       "\n",
       "   split4_test_score  split4_train_score  std_fit_time  std_score_time  \\\n",
       "0               1.00                1.00          0.05            0.00   \n",
       "1               1.00                1.00          0.07            0.01   \n",
       "2               1.00                1.00          0.10            0.00   \n",
       "3               1.00                1.00          0.03            0.00   \n",
       "\n",
       "   std_test_score  std_train_score  \n",
       "0            0.00             0.00  \n",
       "1            0.00             0.00  \n",
       "2            0.00             0.00  \n",
       "3            0.00             0.00  \n",
       "\n",
       "[4 rows x 21 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# scores of GridSearch CV\n",
    "scores = rf.cv_results_\n",
    "pd.DataFrame(scores).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgsAAAFhCAYAAAD+2OlvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nERERsUthQUREROxSWBARERG7/hc8pBfL3FIFdAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 576x396 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plotting accuracies with max_depth\n",
    "plt.figure()\n",
    "plt.plot(scores[\"param_max_depth\"], \n",
    "         scores[\"mean_train_score\"], \n",
    "         label=\"training accuracy\")\n",
    "plt.plot(scores[\"param_max_depth\"], \n",
    "         scores[\"mean_test_score\"], \n",
    "         label=\"test accuracy\")\n",
    "plt.xlabel(\"max_depth\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=7, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'n_estimators': range(100, 1500, 400)},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GridSearchCV to find optimal n_estimators\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "# specify number of folds for k-fold CV\n",
    "n_folds = 5\n",
    "\n",
    "# parameters to build the model on\n",
    "parameters = {'n_estimators': range(100, 1500, 400)}\n",
    "\n",
    "# instantiate the model (note we are specifying a max_depth)\n",
    "rf = RandomForestClassifier(max_depth=7)\n",
    "\n",
    "\n",
    "# fit tree on training data\n",
    "rf = GridSearchCV(rf, parameters, \n",
    "                    cv=n_folds, \n",
    "                   scoring=\"accuracy\")\n",
    "rf.fit(X_train_transformed, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.16</td>\n",
       "      <td>0.11</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>100</td>\n",
       "      <td>{'n_estimators': 100}</td>\n",
       "      <td>1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.62</td>\n",
       "      <td>0.31</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>500</td>\n",
       "      <td>{'n_estimators': 500}</td>\n",
       "      <td>1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>5.67</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29.97</td>\n",
       "      <td>0.47</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>900</td>\n",
       "      <td>{'n_estimators': 900}</td>\n",
       "      <td>1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>43.40</td>\n",
       "      <td>0.70</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1300</td>\n",
       "      <td>{'n_estimators': 1300}</td>\n",
       "      <td>1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  mean_score_time  mean_test_score  mean_train_score  \\\n",
       "0           6.16             0.11             1.00              1.00   \n",
       "1          20.62             0.31             1.00              1.00   \n",
       "2          29.97             0.47             1.00              1.00   \n",
       "3          43.40             0.70             1.00              1.00   \n",
       "\n",
       "  param_n_estimators                  params  rank_test_score  \\\n",
       "0                100   {'n_estimators': 100}                1   \n",
       "1                500   {'n_estimators': 500}                1   \n",
       "2                900   {'n_estimators': 900}                1   \n",
       "3               1300  {'n_estimators': 1300}                1   \n",
       "\n",
       "   split0_test_score  split0_train_score  split1_test_score       ...         \\\n",
       "0               1.00                1.00               1.00       ...          \n",
       "1               1.00                1.00               1.00       ...          \n",
       "2               1.00                1.00               1.00       ...          \n",
       "3               1.00                1.00               1.00       ...          \n",
       "\n",
       "   split2_test_score  split2_train_score  split3_test_score  \\\n",
       "0               1.00                1.00               1.00   \n",
       "1               1.00                1.00               1.00   \n",
       "2               1.00                1.00               1.00   \n",
       "3               1.00                1.00               1.00   \n",
       "\n",
       "   split3_train_score  split4_test_score  split4_train_score  std_fit_time  \\\n",
       "0                1.00               1.00                1.00          0.28   \n",
       "1                1.00               1.00                1.00          5.67   \n",
       "2                1.00               1.00                1.00          0.66   \n",
       "3                1.00               1.00                1.00          0.52   \n",
       "\n",
       "   std_score_time  std_test_score  std_train_score  \n",
       "0            0.00            0.00             0.00  \n",
       "1            0.09            0.00             0.00  \n",
       "2            0.01            0.00             0.00  \n",
       "3            0.04            0.00             0.00  \n",
       "\n",
       "[4 rows x 21 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# scores of GridSearch CV\n",
    "scores = rf.cv_results_\n",
    "pd.DataFrame(scores).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# plotting accuracies with n_estimators\n",
    "plt.figure()\n",
    "plt.plot(scores[\"param_n_estimators\"], \n",
    "         scores[\"mean_train_score\"], \n",
    "         label=\"training accuracy\")\n",
    "plt.plot(scores[\"param_n_estimators\"], \n",
    "         scores[\"mean_test_score\"], \n",
    "         label=\"test accuracy\")\n",
    "plt.xlabel(\"n_estimators\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# GridSearchCV to find optimal max_features\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "# specify number of folds for k-fold CV\n",
    "n_folds = 5\n",
    "\n",
    "# parameters to build the model on\n",
    "parameters = {'max_features': [4, 8, 14, 20, 24]}\n",
    "\n",
    "# instantiate the model\n",
    "rf = RandomForestClassifier(max_depth=4)\n",
    "\n",
    "\n",
    "# fit tree on training data\n",
    "rf = GridSearchCV(rf, parameters, \n",
    "                    cv=n_folds, \n",
    "                   scoring=\"accuracy\")\n",
    "rf.fit(X_train_transformed, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# scores of GridSearch CV\n",
    "scores = rf.cv_results_\n",
    "pd.DataFrame(scores).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# plotting accuracies with max_features\n",
    "plt.figure()\n",
    "plt.plot(scores[\"param_max_features\"], \n",
    "         scores[\"mean_train_score\"], \n",
    "         label=\"training accuracy\")\n",
    "plt.plot(scores[\"param_max_features\"], \n",
    "         scores[\"mean_test_score\"], \n",
    "         label=\"test accuracy\")\n",
    "plt.xlabel(\"max_features\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# GridSearchCV to find optimal min_samples_leaf\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "# specify number of folds for k-fold CV\n",
    "n_folds = 5\n",
    "\n",
    "# parameters to build the model on\n",
    "parameters = {'min_samples_leaf': range(100, 400, 50)}\n",
    "\n",
    "# instantiate the model\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "\n",
    "# fit tree on training data\n",
    "rf = GridSearchCV(rf, parameters, \n",
    "                    cv=n_folds, \n",
    "                   scoring=\"accuracy\")\n",
    "rf.fit(X_train_transformed, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# scores of GridSearch CV\n",
    "scores = rf.cv_results_\n",
    "pd.DataFrame(scores).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# plotting accuracies with min_samples_leaf\n",
    "plt.figure()\n",
    "plt.plot(scores[\"param_min_samples_leaf\"], \n",
    "         scores[\"mean_train_score\"], \n",
    "         label=\"training accuracy\")\n",
    "plt.plot(scores[\"param_min_samples_leaf\"], \n",
    "         scores[\"mean_test_score\"], \n",
    "         label=\"test accuracy\")\n",
    "plt.xlabel(\"min_samples_leaf\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# GridSearchCV to find optimal min_samples_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "# specify number of folds for k-fold CV\n",
    "n_folds = 5\n",
    "\n",
    "# parameters to build the model on\n",
    "parameters = {'min_samples_split': range(200, 500, 50)}\n",
    "\n",
    "# instantiate the model\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "\n",
    "# fit tree on training data\n",
    "rf = GridSearchCV(rf, parameters, \n",
    "                    cv=n_folds, \n",
    "                   scoring=\"accuracy\")\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# scores of GridSearch CV\n",
    "scores = rf.cv_results_\n",
    "pd.DataFrame(scores).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# plotting accuracies with min_samples_split\n",
    "plt.figure()\n",
    "plt.plot(scores[\"param_min_samples_split\"], \n",
    "         scores[\"mean_train_score\"], \n",
    "         label=\"training accuracy\")\n",
    "plt.plot(scores[\"param_min_samples_split\"], \n",
    "         scores[\"mean_test_score\"], \n",
    "         label=\"test accuracy\")\n",
    "plt.xlabel(\"min_samples_split\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create the parameter grid based on the results of random search \n",
    "param_grid = {\n",
    "    'max_depth': [4,8,10],\n",
    "    'min_samples_leaf': range(100, 400, 200),\n",
    "    'min_samples_split': range(200, 500, 200),\n",
    "    'n_estimators': [100,200, 300], \n",
    "    'max_features': [5, 10]\n",
    "}\n",
    "# Create a based model\n",
    "rf = RandomForestClassifier()\n",
    "# Instantiate the grid search model\n",
    "grid_search = GridSearchCV(estimator = rf, param_grid = param_grid, \n",
    "                          cv = 3, n_jobs = -1,verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Fit the grid search to the data\n",
    "grid_search.fit(X_train_transformed, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# printing the optimal accuracy score and hyperparameters\n",
    "print('We can get accuracy of',grid_search.best_score_,'using',grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# model with the best hyperparameters\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc = RandomForestClassifier(bootstrap=True,\n",
    "                             max_depth=10,\n",
    "                             min_samples_leaf=100, \n",
    "                             min_samples_split=200,\n",
    "                             max_features=10,\n",
    "                             n_estimators=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fit\n",
    "rfc.fit(X_train_transformed,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# predict\n",
    "predictions = rfc.predict(X_test_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# evaluation metrics\n",
    "from sklearn.metrics import classification_report,confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(confusion_matrix(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# applying decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=5,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            presort=False, random_state=None, splitter='best')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_default = DecisionTreeClassifier(max_depth=5)\n",
    "dt_default.fit(X_train_transformed, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      0.99      0.97      8128\n",
      "          1       0.59      0.26      0.36       531\n",
      "\n",
      "avg / total       0.93      0.94      0.93      8659\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred_default = dt_default.predict(X_test_transformed)\n",
    "\n",
    "# Printing classification report\n",
    "print(classification_report(y_test, y_pred_default))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
